{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://raw.githubusercontent.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection/master/Sarcasm_Headlines_Dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Python 3.7.7\n"
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "text",
    "id": "pp68FAQf9aMN"
   },
   "outputs": [],
   "source": [
    "# # Sarcasm Detection **Acknowledgement**\n",
    "\n",
    "# Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
    "\n",
    "# **Required Files given in below link.**\n",
    "\n",
    "# https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3Wj_mIZ8S3K"
   },
   "source": [
    "## Install `Tensorflow2.0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW2Uk8otQvi8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !!pip uninstall tensorflow\n",
    "# !pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9kv9tyJ77eF"
   },
   "source": [
    "## Get Required Files from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "D0O_n6OIEVyL",
    "outputId": "3d02fc9c-2fb9-4e05-d74a-a0f457b5e601"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgRpOvFMjKR"
   },
   "outputs": [],
   "source": [
    "#Set your project path \n",
    "# project_path =  ## Add your path here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXYwajPeQbRq"
   },
   "source": [
    "#**## Reading and Exploring Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAk6BRUh8CqL"
   },
   "source": [
    "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n",
    "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StSLB-T8PuGr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_df = pd.read_json(\"Sarcasm_Headlines_Dataset.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   is_sarcastic                                           headline  \\\n0             1  thirtysomething scientists unveil doomsday clo...   \n1             0  dem rep. totally nails why congress is falling...   \n2             0  eat your veggies: 9 deliciously different recipes   \n3             1  inclement weather prevents liar from getting t...   \n4             1  mother comes pretty close to using word 'strea...   \n\n                                        article_link  \n0  https://www.theonion.com/thirtysomething-scien...  \n1  https://www.huffingtonpost.com/entry/donna-edw...  \n2  https://www.huffingtonpost.com/entry/eat-your-...  \n3  https://local.theonion.com/inclement-weather-p...  \n4  https://www.theonion.com/mother-comes-pretty-c...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_sarcastic</th>\n      <th>headline</th>\n      <th>article_link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>thirtysomething scientists unveil doomsday clo...</td>\n      <td>https://www.theonion.com/thirtysomething-scien...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>dem rep. totally nails why congress is falling...</td>\n      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>eat your veggies: 9 deliciously different recipes</td>\n      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>inclement weather prevents liar from getting t...</td>\n      <td>https://local.theonion.com/inclement-weather-p...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>mother comes pretty close to using word 'strea...</td>\n      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "headlines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28619 entries, 0 to 28618\nData columns (total 3 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   is_sarcastic  28619 non-null  int64 \n 1   headline      28619 non-null  object\n 2   article_link  28619 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 670.9+ KB\n"
    }
   ],
   "source": [
    "headlines_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6pXf7A78E2H"
   },
   "source": [
    "## Drop `article_link` from dataset. ( 2 marks)\n",
    "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLSVsvrlP9qD",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28619 entries, 0 to 28618\nData columns (total 2 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   is_sarcastic  28619 non-null  int64 \n 1   headline      28619 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 447.3+ KB\n"
    }
   ],
   "source": [
    "headlines_df.drop(['article_link'],axis=1,inplace=True)\n",
    "headlines_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0h6IOxU8OdH"
   },
   "source": [
    "## Get the Length of each line and find the maximum length. ( 4 marks)\n",
    "As different lines are of different length. We need to pad the our sequences using the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRAsChZAQmr3",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28619 entries, 0 to 28618\nData columns (total 3 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   is_sarcastic  28619 non-null  int64 \n 1   headline      28619 non-null  object\n 2   length        28619 non-null  int64 \ndtypes: int64(2), object(1)\nmemory usage: 670.9+ KB\n"
    }
   ],
   "source": [
    "headlines_df['length'] = headlines_df['headline'].apply(lambda headline: len(headline.split(\" \")))\n",
    "headlines_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   is_sarcastic                                           headline  length\n0             1  thirtysomething scientists unveil doomsday clo...       8\n1             0  dem rep. totally nails why congress is falling...      13\n2             0  eat your veggies: 9 deliciously different recipes       7\n3             1  inclement weather prevents liar from getting t...       8\n4             1  mother comes pretty close to using word 'strea...       9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_sarcastic</th>\n      <th>headline</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>thirtysomething scientists unveil doomsday clo...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>dem rep. totally nails why congress is falling...</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>eat your veggies: 9 deliciously different recipes</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>inclement weather prevents liar from getting t...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>mother comes pretty close to using word 'strea...</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "headlines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPPd0YuPXi2M"
   },
   "source": [
    "#**## Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35abKfRx8as3"
   },
   "source": [
    "## Import required modules required for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVel73hYEV4r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ziybaD1RdD9"
   },
   "source": [
    "# Set Different Parameters for the model. ( 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 25\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9abSe-bM8fn9"
   },
   "source": [
    "## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n",
    "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
    "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9Ad26HfTFMS"
   },
   "outputs": [],
   "source": [
    "t = Tokenizer(num_words=max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts(list(headlines_df['headline']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ffi63KsST3P"
   },
   "source": [
    "# Define X and y for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnjxBdqmSS4s",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of Samples: 28619\n[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0  354 3166 7473 2643    2  660 1118]\nNumber of Labels:  28619\n1\n"
    }
   ],
   "source": [
    "X = t.texts_to_sequences(headlines_df['headline'])\n",
    "X = pad_sequences(X, maxlen = maxlen)\n",
    "y = np.asarray(headlines_df['is_sarcastic'])\n",
    "\n",
    "print(\"Number of Samples:\", len(X))\n",
    "print(X[0])\n",
    "print(\"Number of Labels: \", len(y))\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJLyKg-98rH_"
   },
   "source": [
    "## Get the Vocabulary size ( 2 marks)\n",
    "Hint : You can use tokenizer.word_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-2w0gHEUUIo",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Vocabulary size is  30885\n"
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "print(\"Vocabulary size is \",vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hjeMi40XcB1"
   },
   "source": [
    "**Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUF1TuQa8ux0"
   },
   "source": [
    "## Get Glove Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vq5AIfRtMeZh"
   },
   "outputs": [],
   "source": [
    "# glove_file = project_path + \"glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJLX_n2WMecA"
   },
   "outputs": [],
   "source": [
    "# #Extract Glove embedding zip file\n",
    "# from zipfile import ZipFile\n",
    "# with ZipFile(glove_file, 'r') as z:\n",
    "#   z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IuXlu8-U3HG"
   },
   "source": [
    "# Get the Word Embeddings using Embedding file as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elZ-T5aFGZmZ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'glove.6B.200d.txt'\n",
    "\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE, encoding=\"utf8\"):\n",
    "    word = o.split(\" \")[0]\n",
    "    # print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    # print(embd)\n",
    "    embeddings[word] = embd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTPxveDmVCrA"
   },
   "source": [
    "# Create a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQgOhiywU9nU"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "400000"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 200))\n",
    "\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "len(embeddings.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7IbWuEX82Ra"
   },
   "source": [
    "## Create and Compile your Model  ( 7 marks)\n",
    "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
    "In the end add a final dense layer with sigmoid activation for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7jhsSgYXG4l"
   },
   "outputs": [],
   "source": [
    "### Embedding layer for hint \n",
    "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
    "### Bidirectional LSTM layer for hint \n",
    "## model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, weights = [embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJFMxZwMWoTw"
   },
   "source": [
    "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpVkajCcWnRK",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 22895 samples, validate on 5724 samples\nEpoch 1/5\n22895/22895 [==============================] - 27s 1ms/sample - loss: 0.4459 - accuracy: 0.7825 - val_loss: 0.3404 - val_accuracy: 0.8522\nEpoch 2/5\n22895/22895 [==============================] - 18s 801us/sample - loss: 0.2552 - accuracy: 0.8950 - val_loss: 0.3098 - val_accuracy: 0.8680\nEpoch 3/5\n22895/22895 [==============================] - 18s 804us/sample - loss: 0.1750 - accuracy: 0.9324 - val_loss: 0.3274 - val_accuracy: 0.8625\nEpoch 4/5\n22895/22895 [==============================] - 18s 805us/sample - loss: 0.1206 - accuracy: 0.9554 - val_loss: 0.3772 - val_accuracy: 0.8614\nEpoch 5/5\n22895/22895 [==============================] - 18s 804us/sample - loss: 0.0828 - accuracy: 0.9706 - val_loss: 0.4224 - val_accuracy: 0.8584\n"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "## Add your code here ##\n",
    "detectingModel = model.fit(X, y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, weights = [embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 22895 samples, validate on 5724 samples\nEpoch 1/5\n22895/22895 [==============================] - 24s 1ms/sample - loss: 0.4688 - accuracy: 0.7807 - val_loss: 0.3319 - val_accuracy: 0.8525\nEpoch 2/5\n22895/22895 [==============================] - 18s 801us/sample - loss: 0.2805 - accuracy: 0.8921 - val_loss: 0.3101 - val_accuracy: 0.8663\nEpoch 3/5\n22895/22895 [==============================] - 18s 806us/sample - loss: 0.1956 - accuracy: 0.9298 - val_loss: 0.3433 - val_accuracy: 0.8627\nEpoch 4/5\n22895/22895 [==============================] - 18s 802us/sample - loss: 0.1348 - accuracy: 0.9523 - val_loss: 0.4339 - val_accuracy: 0.8625\nEpoch 5/5\n22895/22895 [==============================] - 18s 806us/sample - loss: 0.0949 - accuracy: 0.9674 - val_loss: 0.6805 - val_accuracy: 0.8596\n"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "## Add your code here ##\n",
    "detectingModel = model.fit(X, y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interestingly, adding dropout increases the val accuracy a bit more."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Sarcasm_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}