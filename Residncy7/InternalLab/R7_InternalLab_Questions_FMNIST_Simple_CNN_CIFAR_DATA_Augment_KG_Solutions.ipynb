{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment_KG_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEAhrS9LTtRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras  \n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense,Dropout,Activation,Flatten,Reshape\n",
        "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ab53d06-c1ed-4636-9103-07735b41e95d"
      },
      "source": [
        "print(\"no. of samples in train : \",x_train.shape[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of samples in train :  60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zewyDcBlJjv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9bb539e-77de-4f65-a566-4548d844a20e"
      },
      "source": [
        "print(\"no. of samples in test : \",x_test.shape[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of samples in test :  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88590762-b60a-416d-88f2-90c878b24cd7"
      },
      "source": [
        "print(\"the dimensions of an image in the dataset \",x_train[0].shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the dimensions of an image in the dataset  (28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c5e5f81-b97f-436a-b483-15b7dac630e9"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3119131b-5214-49d3-9fa7-5a220cf3507f"
      },
      "source": [
        "print(x_train[0])\n",
        "print(x_test[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.         0.05098039 0.28627452 0.\n",
            "  0.         0.00392157 0.01568628 0.         0.         0.\n",
            "  0.         0.00392157 0.00392157 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.         0.14117648 0.53333336 0.49803922 0.24313726\n",
            "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
            "  0.01568628 0.         0.         0.01176471]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.02352941 0.         0.4        0.8        0.6901961  0.5254902\n",
            "  0.5647059  0.48235294 0.09019608 0.         0.         0.\n",
            "  0.         0.04705882 0.03921569 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60784316 0.9254902  0.8117647  0.69803923\n",
            "  0.41960785 0.6117647  0.6313726  0.42745098 0.2509804  0.09019608\n",
            "  0.3019608  0.50980395 0.28235295 0.05882353]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.27058825 0.8117647  0.8745098  0.85490197 0.84705883\n",
            "  0.84705883 0.6392157  0.49803922 0.4745098  0.47843137 0.57254905\n",
            "  0.5529412  0.34509805 0.6745098  0.25882354]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
            "  0.         0.78431374 0.9098039  0.9098039  0.9137255  0.8980392\n",
            "  0.8745098  0.8745098  0.84313726 0.8352941  0.6431373  0.49803922\n",
            "  0.48235294 0.76862746 0.8980392  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.7176471  0.88235295 0.84705883 0.8745098  0.89411765\n",
            "  0.92156863 0.8901961  0.8784314  0.87058824 0.8784314  0.8666667\n",
            "  0.8745098  0.9607843  0.6784314  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.75686276 0.89411765 0.85490197 0.8352941  0.7764706\n",
            "  0.7058824  0.83137256 0.8235294  0.827451   0.8352941  0.8745098\n",
            "  0.8627451  0.9529412  0.7921569  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.01176471 0.\n",
            "  0.04705882 0.85882354 0.8627451  0.83137256 0.85490197 0.7529412\n",
            "  0.6627451  0.8901961  0.8156863  0.85490197 0.8784314  0.83137256\n",
            "  0.8862745  0.77254903 0.81960785 0.20392157]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.02352941 0.\n",
            "  0.3882353  0.95686275 0.87058824 0.8627451  0.85490197 0.79607844\n",
            "  0.7764706  0.8666667  0.84313726 0.8352941  0.87058824 0.8627451\n",
            "  0.9607843  0.46666667 0.654902   0.21960784]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.01568628 0.         0.\n",
            "  0.21568628 0.9254902  0.89411765 0.9019608  0.89411765 0.9411765\n",
            "  0.9098039  0.8352941  0.85490197 0.8745098  0.91764706 0.8509804\n",
            "  0.8509804  0.81960785 0.36078432 0.        ]\n",
            " [0.         0.         0.00392157 0.01568628 0.02352941 0.02745098\n",
            "  0.00784314 0.         0.         0.         0.         0.\n",
            "  0.92941177 0.8862745  0.8509804  0.8745098  0.87058824 0.85882354\n",
            "  0.87058824 0.8666667  0.84705883 0.8745098  0.8980392  0.84313726\n",
            "  0.85490197 1.         0.3019608  0.        ]\n",
            " [0.         0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.24313726 0.5686275  0.8\n",
            "  0.89411765 0.8117647  0.8352941  0.8666667  0.85490197 0.8156863\n",
            "  0.827451   0.85490197 0.8784314  0.8745098  0.85882354 0.84313726\n",
            "  0.8784314  0.95686275 0.62352943 0.        ]\n",
            " [0.         0.         0.         0.         0.07058824 0.17254902\n",
            "  0.32156864 0.41960785 0.7411765  0.89411765 0.8627451  0.87058824\n",
            "  0.8509804  0.8862745  0.78431374 0.8039216  0.827451   0.9019608\n",
            "  0.8784314  0.91764706 0.6901961  0.7372549  0.98039216 0.972549\n",
            "  0.9137255  0.93333334 0.84313726 0.        ]\n",
            " [0.         0.22352941 0.73333335 0.8156863  0.8784314  0.8666667\n",
            "  0.8784314  0.8156863  0.8        0.8392157  0.8156863  0.81960785\n",
            "  0.78431374 0.62352943 0.9607843  0.75686276 0.80784315 0.8745098\n",
            "  1.         1.         0.8666667  0.91764706 0.8666667  0.827451\n",
            "  0.8627451  0.9098039  0.9647059  0.        ]\n",
            " [0.01176471 0.7921569  0.89411765 0.8784314  0.8666667  0.827451\n",
            "  0.827451   0.8392157  0.8039216  0.8039216  0.8039216  0.8627451\n",
            "  0.9411765  0.3137255  0.5882353  1.         0.8980392  0.8666667\n",
            "  0.7372549  0.6039216  0.7490196  0.8235294  0.8        0.81960785\n",
            "  0.87058824 0.89411765 0.88235295 0.        ]\n",
            " [0.38431373 0.9137255  0.7764706  0.8235294  0.87058824 0.8980392\n",
            "  0.8980392  0.91764706 0.9764706  0.8627451  0.7607843  0.84313726\n",
            "  0.8509804  0.94509804 0.25490198 0.28627452 0.41568628 0.45882353\n",
            "  0.65882355 0.85882354 0.8666667  0.84313726 0.8509804  0.8745098\n",
            "  0.8745098  0.8784314  0.8980392  0.11372549]\n",
            " [0.29411766 0.8        0.83137256 0.8        0.75686276 0.8039216\n",
            "  0.827451   0.88235295 0.84705883 0.7254902  0.77254903 0.80784315\n",
            "  0.7764706  0.8352941  0.9411765  0.7647059  0.8901961  0.9607843\n",
            "  0.9372549  0.8745098  0.85490197 0.83137256 0.81960785 0.87058824\n",
            "  0.8627451  0.8666667  0.9019608  0.2627451 ]\n",
            " [0.1882353  0.79607844 0.7176471  0.7607843  0.8352941  0.77254903\n",
            "  0.7254902  0.74509805 0.7607843  0.7529412  0.7921569  0.8392157\n",
            "  0.85882354 0.8666667  0.8627451  0.9254902  0.88235295 0.84705883\n",
            "  0.78039217 0.80784315 0.7294118  0.70980394 0.69411767 0.6745098\n",
            "  0.70980394 0.8039216  0.80784315 0.4509804 ]\n",
            " [0.         0.47843137 0.85882354 0.75686276 0.7019608  0.67058825\n",
            "  0.7176471  0.76862746 0.8        0.8235294  0.8352941  0.8117647\n",
            "  0.827451   0.8235294  0.78431374 0.76862746 0.7607843  0.7490196\n",
            "  0.7647059  0.7490196  0.7764706  0.7529412  0.6901961  0.6117647\n",
            "  0.654902   0.69411767 0.8235294  0.36078432]\n",
            " [0.         0.         0.2901961  0.7411765  0.83137256 0.7490196\n",
            "  0.6862745  0.6745098  0.6862745  0.70980394 0.7254902  0.7372549\n",
            "  0.7411765  0.7372549  0.75686276 0.7764706  0.8        0.81960785\n",
            "  0.8235294  0.8235294  0.827451   0.7372549  0.7372549  0.7607843\n",
            "  0.7529412  0.84705883 0.6666667  0.        ]\n",
            " [0.00784314 0.         0.         0.         0.25882354 0.78431374\n",
            "  0.87058824 0.92941177 0.9372549  0.9490196  0.9647059  0.9529412\n",
            "  0.95686275 0.8666667  0.8627451  0.75686276 0.7490196  0.7019608\n",
            "  0.7137255  0.7137255  0.70980394 0.6901961  0.6509804  0.65882355\n",
            "  0.3882353  0.22745098 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.15686275 0.23921569 0.17254902 0.28235295 0.16078432\n",
            "  0.13725491 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01176471 0.00392157 0.         0.         0.02745098\n",
            "  0.         0.14509805 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.00784314 0.         0.10588235 0.32941177\n",
            "  0.04313726 0.         0.         0.         0.         0.\n",
            "  0.         0.46666667 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.         0.         0.34509805 0.56078434\n",
            "  0.43137255 0.         0.         0.         0.         0.08627451\n",
            "  0.3647059  0.41568628 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01568628 0.         0.20784314 0.5058824  0.47058824\n",
            "  0.5764706  0.6862745  0.6156863  0.6509804  0.5294118  0.6039216\n",
            "  0.65882355 0.54901963 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00784314 0.         0.04313726 0.5372549  0.50980395 0.5019608\n",
            "  0.627451   0.6901961  0.62352943 0.654902   0.69803923 0.58431375\n",
            "  0.5921569  0.5647059  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.00784314 0.00392157 0.         0.01176471\n",
            "  0.         0.         0.4509804  0.44705883 0.41568628 0.5372549\n",
            "  0.65882355 0.6        0.6117647  0.64705884 0.654902   0.56078434\n",
            "  0.6156863  0.61960787 0.04313726 0.        ]\n",
            " [0.         0.         0.         0.         0.00392157 0.\n",
            "  0.         0.         0.         0.         0.01176471 0.\n",
            "  0.         0.34901962 0.54509807 0.3529412  0.36862746 0.6\n",
            "  0.58431375 0.5137255  0.5921569  0.6627451  0.6745098  0.56078434\n",
            "  0.62352943 0.6627451  0.1882353  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.00784314 0.01568628 0.00392157 0.         0.         0.\n",
            "  0.38431373 0.53333336 0.43137255 0.42745098 0.43137255 0.63529414\n",
            "  0.5294118  0.5647059  0.58431375 0.62352943 0.654902   0.5647059\n",
            "  0.61960787 0.6627451  0.46666667 0.        ]\n",
            " [0.         0.         0.00784314 0.00784314 0.00392157 0.00784314\n",
            "  0.         0.         0.         0.         0.10196079 0.42352942\n",
            "  0.45882353 0.3882353  0.43529412 0.45882353 0.53333336 0.6117647\n",
            "  0.5254902  0.6039216  0.6039216  0.6117647  0.627451   0.5529412\n",
            "  0.5764706  0.6117647  0.69803923 0.        ]\n",
            " [0.01176471 0.         0.         0.         0.         0.\n",
            "  0.         0.08235294 0.20784314 0.36078432 0.45882353 0.43529412\n",
            "  0.40392157 0.4509804  0.5058824  0.5254902  0.56078434 0.6039216\n",
            "  0.64705884 0.6666667  0.6039216  0.5921569  0.6039216  0.56078434\n",
            "  0.5411765  0.5882353  0.64705884 0.16862746]\n",
            " [0.         0.         0.09019608 0.21176471 0.25490198 0.29803923\n",
            "  0.33333334 0.4627451  0.5019608  0.48235294 0.43529412 0.44313726\n",
            "  0.4627451  0.49803922 0.49019608 0.54509807 0.52156866 0.53333336\n",
            "  0.627451   0.54901963 0.60784316 0.6313726  0.5647059  0.60784316\n",
            "  0.6745098  0.6313726  0.7411765  0.24313726]\n",
            " [0.         0.26666668 0.36862746 0.3529412  0.43529412 0.44705883\n",
            "  0.43529412 0.44705883 0.4509804  0.49803922 0.5294118  0.53333336\n",
            "  0.56078434 0.49411765 0.49803922 0.5921569  0.6039216  0.56078434\n",
            "  0.5803922  0.49019608 0.63529414 0.63529414 0.5647059  0.5411765\n",
            "  0.6        0.63529414 0.76862746 0.22745098]\n",
            " [0.27450982 0.6627451  0.5058824  0.40784314 0.38431373 0.39215687\n",
            "  0.36862746 0.38039216 0.38431373 0.4        0.42352942 0.41568628\n",
            "  0.46666667 0.47058824 0.5058824  0.58431375 0.6117647  0.654902\n",
            "  0.74509805 0.74509805 0.76862746 0.7764706  0.7764706  0.73333335\n",
            "  0.77254903 0.7411765  0.72156864 0.14117648]\n",
            " [0.0627451  0.49411765 0.67058825 0.7372549  0.7372549  0.72156864\n",
            "  0.67058825 0.6        0.5294118  0.47058824 0.49411765 0.49803922\n",
            "  0.57254905 0.7254902  0.7647059  0.81960785 0.8156863  1.\n",
            "  0.81960785 0.69411767 0.9607843  0.9882353  0.9843137  0.9843137\n",
            "  0.96862745 0.8627451  0.80784315 0.19215687]\n",
            " [0.         0.         0.         0.04705882 0.2627451  0.41568628\n",
            "  0.6431373  0.7254902  0.78039217 0.8235294  0.827451   0.8235294\n",
            "  0.8156863  0.74509805 0.5882353  0.32156864 0.03137255 0.\n",
            "  0.         0.         0.69803923 0.8156863  0.7372549  0.6862745\n",
            "  0.63529414 0.61960787 0.5921569  0.04313726]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb2bad69-a176-498a-d6e4-d9e7fa1ed808"
      },
      "source": [
        "print(\"already imported at the beginning...\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already imported at the beginning...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "3709046f-d312-4a9d-d2a3-2e860b0441f8"
      },
      "source": [
        "TRAIN = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# Define model\n",
        "model_1 = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model_1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "# 2nd Conv Layer\n",
        "model_1.add(Convolution2D(32, 3, 3))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(128))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "# Prediction Layer\n",
        "model_1.add(Dense(10))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "# Loss and Optimizer\n",
        "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Store Training Results\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]\n",
        "\n",
        "# Train the model_1\n",
        "model_1.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "        validation_data=(x_test, y_test), callbacks=callback_list)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.3631 - acc: 0.8685 - val_loss: 0.2915 - val_acc: 0.8908\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.2247 - acc: 0.9165 - val_loss: 0.2569 - val_acc: 0.9085\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.1641 - acc: 0.9388 - val_loss: 0.2341 - val_acc: 0.9179\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.1129 - acc: 0.9580 - val_loss: 0.2670 - val_acc: 0.9133\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0744 - acc: 0.9735 - val_loss: 0.2970 - val_acc: 0.9132\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0498 - acc: 0.9820 - val_loss: 0.3735 - val_acc: 0.9168\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0338 - acc: 0.9879 - val_loss: 0.3685 - val_acc: 0.9145\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0283 - acc: 0.9896 - val_loss: 0.4195 - val_acc: 0.9147\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3510413358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLO3YJ90W2T5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "0005c66a-2d54-4331-9bf1-4280de59006f"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               2359424   \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,370,282\n",
            "Trainable params: 2,370,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "c8d9aa23-00f2-4bb8-cdb8-8a98570a698e"
      },
      "source": [
        "# Define Model\n",
        "model_2 = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model_2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "# 2nd Conv Layer\n",
        "model_2.add(Convolution2D(32, 3, 3))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "# Max Pooling\n",
        "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Dropout\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(128))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "# More Dropout\n",
        "model_2.add(Dropout(0.5))\n",
        "\n",
        "# Prediction Layer\n",
        "model_2.add(Dense(10))\n",
        "model_2.add(Activation('softmax'))\n",
        "\n",
        "# Loss and Optimizer\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Store Training Results\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]\n",
        "\n",
        "# Train the model\n",
        "model_2.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "        validation_data=(x_test, y_test), callbacks=callback_list)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.5147 - acc: 0.8171 - val_loss: 0.3473 - val_acc: 0.8691\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.3540 - acc: 0.8732 - val_loss: 0.2882 - val_acc: 0.8947\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.3064 - acc: 0.8888 - val_loss: 0.2616 - val_acc: 0.9043\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.2754 - acc: 0.9002 - val_loss: 0.2472 - val_acc: 0.9070\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.2519 - acc: 0.9066 - val_loss: 0.2382 - val_acc: 0.9117\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 0.2338 - acc: 0.9140 - val_loss: 0.2446 - val_acc: 0.9108\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 0.2195 - acc: 0.9189 - val_loss: 0.2305 - val_acc: 0.9145\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.2080 - acc: 0.9228 - val_loss: 0.2166 - val_acc: 0.9219\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.1981 - acc: 0.9251 - val_loss: 0.2231 - val_acc: 0.9197\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.1921 - acc: 0.9283 - val_loss: 0.2173 - val_acc: 0.9219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f351013d3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkLAH4qrX0qN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "9049fb16-f46a-4393-bab5-ce38e85f13b7"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 600,810\n",
            "Trainable params: 600,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  \n",
        "    samplewise_center=False,  \n",
        "    featurewise_std_normalization=False,  \n",
        "    samplewise_std_normalization=False,  \n",
        "    zca_whitening=False,  \n",
        "    rotation_range=50,  \n",
        "    width_shift_range=0.2,  \n",
        "    height_shift_range=0.2,  \n",
        "    horizontal_flip=False,  \n",
        "    vertical_flip=False)  \n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "04661704-72c6-4845-87fd-6bd4ee9f24ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJNqI/wCX2axSIRcZ/QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "41c5ea77-e310-4e43-b050-8a105d741448"
      },
      "source": [
        "model_2.fit_generator(datagen.flow(x_train, y_train,batch_size=32),\n",
        "                    samples_per_epoch=x_train.shape[0],\n",
        "                    nb_epoch=10,\n",
        "                    validation_data=(x_test, y_test), callbacks=callback_list)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  12/1875 [..............................] - ETA: 20s - loss: 3.3028 - acc: 0.2708"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 22s 12ms/step - loss: 1.1671 - acc: 0.5722 - val_loss: 0.5057 - val_acc: 0.7999\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.8904 - acc: 0.6695 - val_loss: 0.5057 - val_acc: 0.8050\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.8174 - acc: 0.6958 - val_loss: 0.4812 - val_acc: 0.8243\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.7755 - acc: 0.7121 - val_loss: 0.4962 - val_acc: 0.8155\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.7448 - acc: 0.7231 - val_loss: 0.4865 - val_acc: 0.8306\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.7161 - acc: 0.7329 - val_loss: 0.4913 - val_acc: 0.8213\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6957 - acc: 0.7389 - val_loss: 0.5023 - val_acc: 0.8204\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6920 - acc: 0.7445 - val_loss: 0.5152 - val_acc: 0.8141\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6747 - acc: 0.7497 - val_loss: 0.4986 - val_acc: 0.8201\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6617 - acc: 0.7537 - val_loss: 0.5057 - val_acc: 0.8219\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35103719e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "27295798-720a-4988-9c18-68cae7718918"
      },
      "source": [
        "batch_size=32\n",
        "epochs = 10\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=True )\n",
        "loss,accuracy  = model_2.evaluate(x_test, y_test, verbose=True)\n",
        "print(\"The accuracy of the model is :\" , accuracy)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "54000/54000 [==============================] - 10s 190us/step - loss: 0.1485 - acc: 0.9435 - val_loss: 0.1933 - val_acc: 0.9333\n",
            "Epoch 2/10\n",
            "54000/54000 [==============================] - 10s 187us/step - loss: 0.1424 - acc: 0.9474 - val_loss: 0.1839 - val_acc: 0.9372\n",
            "Epoch 3/10\n",
            "54000/54000 [==============================] - 9s 168us/step - loss: 0.1388 - acc: 0.9489 - val_loss: 0.1781 - val_acc: 0.9362\n",
            "Epoch 4/10\n",
            "54000/54000 [==============================] - 10s 177us/step - loss: 0.1297 - acc: 0.9508 - val_loss: 0.1739 - val_acc: 0.9383\n",
            "Epoch 5/10\n",
            "54000/54000 [==============================] - 9s 171us/step - loss: 0.1290 - acc: 0.9512 - val_loss: 0.1857 - val_acc: 0.9372\n",
            "Epoch 6/10\n",
            "54000/54000 [==============================] - 10s 178us/step - loss: 0.1236 - acc: 0.9532 - val_loss: 0.1862 - val_acc: 0.9377\n",
            "Epoch 7/10\n",
            "54000/54000 [==============================] - 10s 177us/step - loss: 0.1219 - acc: 0.9537 - val_loss: 0.2109 - val_acc: 0.9320\n",
            "Epoch 8/10\n",
            "54000/54000 [==============================] - 9s 172us/step - loss: 0.1162 - acc: 0.9547 - val_loss: 0.2016 - val_acc: 0.9397\n",
            "Epoch 9/10\n",
            "54000/54000 [==============================] - 9s 169us/step - loss: 0.1145 - acc: 0.9568 - val_loss: 0.1959 - val_acc: 0.9365\n",
            "Epoch 10/10\n",
            "54000/54000 [==============================] - 10s 180us/step - loss: 0.1126 - acc: 0.9574 - val_loss: 0.2088 - val_acc: 0.9388\n",
            "10000/10000 [==============================] - 1s 52us/step\n",
            "The accuracy of the model is : 0.9316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1145ff41-dc5d-4c3a-99f5-3cc971cd0fec"
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy / loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2bfb706a-a1a4-46e2-9b9c-cfad20280cd4"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec820d04-51f4-4542-80c7-0208d16f96e7"
      },
      "source": [
        "print(\"no. of samples in train : \",x_train.shape[0])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of samples in train :  50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n28ccU6Hp6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1b5f79d-c9c3-43cb-d580-c03e503fc6f0"
      },
      "source": [
        "print(\"no. of samples in test : \",x_test.shape[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of samples in test :  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQg7Hfp6dFWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3).astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  \n",
        "    samplewise_center=False,  \n",
        "    featurewise_std_normalization=False,  \n",
        "    samplewise_std_normalization=False,  \n",
        "    zca_whitening=False,  \n",
        "    rotation_range=50,  \n",
        "    width_shift_range=0.2,  \n",
        "    height_shift_range=0.2,  \n",
        "    horizontal_flip=True,  \n",
        "    vertical_flip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSw8Bv2_4hb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ef8d27a8-4ee1-4811-95a9-161aec01a444"
      },
      "source": [
        "gen = datagen.flow(x_train[:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "\n",
        "plt.plot()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxveRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tegV6pgYe5rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}